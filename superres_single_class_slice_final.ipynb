{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "#\n",
    "# !git clone https://{TOKEN}@github.com/nicoloalbergoni/DeeplabV3Plus-TF2.git\n",
    "# %load_ext tensorboard\n",
    "# %cd ./DeeplabV3Plus-TF2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#!python download_and_prepare_voc.py --remove_cmap --download_berkley"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from model import DeeplabV3Plus\n",
    "import tensorflow_addons as tfa\n",
    "from matplotlib import pyplot as plt\n",
    "from superresolution import Superresolution\n",
    "from utils import load_image, get_prediction, create_mask, plot_prediction\n",
    "from superres_utils import get_img_paths, filter_by_class, min_max_normalization, plot_image, plot_histogram, list_precomputed_data_paths, check_hdf5_validity\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "PASCAL_ROOT = os.path.join(DATA_DIR, \"VOCdevkit\", \"VOC2012\")\n",
    "IMGS_PATH = os.path.join(PASCAL_ROOT, \"JPEGImages\")\n",
    "\n",
    "SUPERRES_ROOT = os.path.join(DATA_DIR, \"superres_root\")\n",
    "PRECOMPUTED_OUTPUT_DIR = os.path.join(SUPERRES_ROOT, \"precomputed_features\")\n",
    "STANDARD_OUTPUT_DIR = os.path.join(SUPERRES_ROOT, \"standard_output\")\n",
    "SUPERRES_OUTPUT_DIR = os.path.join(SUPERRES_ROOT, \"superres_output\")\n",
    "\n",
    "# SEED = np.random.randint(0, 1000)\n",
    "SEED = 1234\n",
    "IMG_SIZE = (512, 512)\n",
    "BATCH_SIZE = 2\n",
    "BUFFER_SIZE = 1000\n",
    "EPOCHS = 30\n",
    "CLASSES = 21\n",
    "RESHAPE_MASKS = True\n",
    "NUM_AUG = 50\n",
    "CLASS_ID = 8\n",
    "NUM_SAMPLES = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid images: 26 (Initial:  300)\n"
     ]
    }
   ],
   "source": [
    "image_list_path = os.path.join(DATA_DIR, \"augmented_file_lists\", \"valaug.txt\")\n",
    "image_paths = get_img_paths(image_list_path, IMGS_PATH)\n",
    "\n",
    "if NUM_SAMPLES is not None:\n",
    "    image_paths = image_paths[:NUM_SAMPLES]\n",
    "\n",
    "images_dict = filter_by_class(image_paths, class_id=CLASS_ID)\n",
    "\n",
    "print(f\"Valid images: {len(images_dict)} (Initial:  {len(image_paths)})\")\n",
    "\n",
    "valid_filenames = list(images_dict.keys())\n",
    "\n",
    "model_no_upsample = DeeplabV3Plus(\n",
    "    input_shape=(512, 512, 3),\n",
    "    classes=21,\n",
    "    OS=16,\n",
    "    last_activation=None,\n",
    "    load_weights=True,\n",
    "    backbone=\"mobilenet\",\n",
    "    alpha=1.).build_model(final_upsample=False)\n",
    "\n",
    "model_standard = DeeplabV3Plus(\n",
    "    input_shape=(512, 512, 3),\n",
    "    classes=21,\n",
    "    OS=16,\n",
    "    last_activation=None,\n",
    "    load_weights=True,\n",
    "    backbone=\"mobilenet\",\n",
    "    alpha=1.).build_model(final_upsample=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute standard output for comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_standard_output(image_dict, model, dest_folder, filter_class_id=None):\n",
    "    standard_masks = {}\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    for key in tqdm(image_dict):\n",
    "        standard_mask = get_prediction(model, image_dict[key])\n",
    "        if filter_class_id is not None:\n",
    "            standard_mask = tf.where(standard_mask == filter_class_id, standard_mask, 0) # Set to 0 all predictions different from the given class\n",
    "        tf.keras.utils.save_img(f\"{dest_folder}/{key}.png\", standard_mask, scale=False)\n",
    "        standard_masks[key] = standard_mask\n",
    "\n",
    "    return standard_masks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:06<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "standard_masks_dict = compute_standard_output(images_dict, model_standard, dest_folder=STANDARD_OUTPUT_DIR, filter_class_id=CLASS_ID)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Precompute Augmented Output Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_augmented_copies(image, num_aug, angle_max, shift_max):\n",
    "\n",
    "    batched_images = tf.tile(tf.expand_dims(image, axis=0), [num_aug, 1, 1, 1])  # Size [num_aug, 512, 512, 3]\n",
    "    angles = np.random.uniform(-angle_max, angle_max, num_aug)\n",
    "    shifts = np.random.uniform(-shift_max, shift_max, (num_aug, 2))\n",
    "    # First sample is not augmented\n",
    "    angles[0] = 0\n",
    "    shifts[0] = np.array([0, 0])\n",
    "    angles = angles.astype(\"float32\")\n",
    "    shifts = shifts.astype(\"float32\")\n",
    "\n",
    "    rotated_images = tfa.image.rotate(batched_images, angles, interpolation=\"bilinear\")\n",
    "    translated_images = tfa.image.translate(rotated_images, shifts, interpolation=\"bilinear\")\n",
    "\n",
    "    return translated_images, angles, shifts\n",
    "\n",
    "def compute_augmented_features(image_filenames, model, dest_folder, filter_class_id, mode=\"slice\", num_aug=100, angle_max=0.5, shift_max=30, save_output=False, relu_output=False):\n",
    "\n",
    "    augmented_features = {}\n",
    "\n",
    "    for filename in tqdm(image_filenames):\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(IMGS_PATH, f\"{filename}.jpg\")\n",
    "        image = load_image(image_path, image_size=IMG_SIZE, normalize=True)\n",
    "\n",
    "        # Create augmented copies\n",
    "        augmented_images, angles, shifts = create_augmented_copies(image, num_aug=num_aug, angle_max=angle_max, shift_max=shift_max)\n",
    "\n",
    "        # Create destination folder\n",
    "        output_folder = os.path.join(dest_folder, filename)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Get model prediction for each aumented copy\n",
    "        predictions = model.predict(augmented_images, batch_size=BATCH_SIZE)\n",
    "\n",
    "        class_masks = []\n",
    "        max_masks = []\n",
    "\n",
    "        for i, prediction in enumerate(predictions):\n",
    "\n",
    "            if mode == \"slice\":\n",
    "                class_slice = prediction[:, :, filter_class_id]\n",
    "                class_mask = class_slice[..., np.newaxis]\n",
    "\n",
    "                no_class_prediction = np.delete(prediction, filter_class_id, axis=-1)\n",
    "                max_mask = no_class_prediction.max(axis=-1)\n",
    "                max_mask = max_mask[..., np.newaxis]\n",
    "\n",
    "                # ReLU is only needed when working with slices\n",
    "                if relu_output:\n",
    "                    class_mask = (tf.nn.relu(class_mask)).numpy()\n",
    "                    max_mask = (tf.nn.relu(max_mask)).numpy()\n",
    "\n",
    "                max_masks.append(max_mask)\n",
    "\n",
    "            elif mode == \"argmax\":\n",
    "                class_mask = create_mask(prediction)\n",
    "                # Set to 0 all predictions different from the given class\n",
    "                class_mask = tf.where(class_mask == filter_class_id, class_mask, 0)\n",
    "                class_mask = tf.cast(class_mask, tf.float32) # Necessary for super-resolution operations\n",
    "                class_mask = class_mask.numpy()\n",
    "\n",
    "            class_masks.append(class_mask)\n",
    "\n",
    "            if save_output:\n",
    "                tf.keras.utils.save_img(f\"{output_folder}/{i}_class.png\", class_mask, scale=True)\n",
    "                if mode == \"slice\":\n",
    "                    tf.keras.utils.save_img(f\"{output_folder}/{i}_max.png\", max_mask, scale=True)\n",
    "\n",
    "            # np.save(os.path.join(output_folder, f\"{filename}_angles\"), angles)\n",
    "            # np.save(os.path.join(output_folder, f\"{filename}_shifts\"), shifts)\n",
    "\n",
    "        file = h5py.File(f\"{output_folder}/{filename}.hdf5\", \"w\")\n",
    "        file.create_dataset(\"class_masks\", data=class_masks)\n",
    "\n",
    "        if mode == \"slice\":\n",
    "            file.create_dataset(\"max_masks\", data=max_masks)\n",
    "\n",
    "        file.create_dataset(\"angles\", data=angles)\n",
    "        file.create_dataset(\"shifts\", data=shifts)\n",
    "        file.attrs[\"filename\"] = filename\n",
    "        file.attrs[\"mode\"] = mode\n",
    "\n",
    "        file.close()\n",
    "\n",
    "        augmented_features[filename] = { \"class\": class_masks, \"max\": max_masks }\n",
    "\n",
    "    return augmented_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:36<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "angle_max = 0.5  # in radians\n",
    "shift_max = 30\n",
    "\n",
    "augmented_features_dict = compute_augmented_features(images_dict, model_no_upsample, mode=\"slice\", dest_folder=PRECOMPUTED_OUTPUT_DIR, filter_class_id=CLASS_ID, num_aug=NUM_AUG, angle_max=angle_max, shift_max=shift_max, save_output=True, relu_output=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute Super-Resolution Output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def threshold_image(class_mask, max_mask=None, th_val=.15):\n",
    "    if max_mask is not None:\n",
    "        th_mask = tf.where(class_mask >= max_mask, CLASS_ID, 0)\n",
    "    else:\n",
    "        sample_th = tf.cast(tf.reduce_max(class_mask), tf.float32) * th_val\n",
    "        th_mask = tf.where(class_mask > sample_th, CLASS_ID, 0)\n",
    "\n",
    "    return th_mask.numpy()\n",
    "\n",
    "\n",
    "def custom_IOU(y_true, y_pred, class_id):\n",
    "    y_true_squeeze = tf.squeeze(y_true)\n",
    "    y_pred_squeeze = tf.squeeze(y_pred)\n",
    "    classes = [0, class_id] # Only check in background and given class\n",
    "\n",
    "    y_true_squeeze = tf.where(y_true_squeeze != class_id, 0, y_true_squeeze)\n",
    "\n",
    "    ious = []\n",
    "    for i in classes:\n",
    "        true_labels = tf.equal(y_true_squeeze, i)\n",
    "        pred_labels = tf.equal(y_pred_squeeze, i)\n",
    "        inter = tf.cast(true_labels & pred_labels, tf.int32)\n",
    "        union = tf.cast(true_labels | pred_labels, tf.int32)\n",
    "\n",
    "        iou = tf.reduce_sum(inter) / tf.reduce_sum(union)\n",
    "        ious.append(iou)\n",
    "\n",
    "    ious = tf.stack(ious)\n",
    "    legal_labels = ~tf.math.is_nan(ious)\n",
    "    ious = tf.gather(ious, indices=tf.where(legal_labels))\n",
    "    return tf.reduce_mean(ious)\n",
    "\n",
    "\n",
    "def evaluate_IOU(true_mask, superres_mask, img_size=(512, 512)):\n",
    "    true_mask = tf.reshape(true_mask, (img_size[0] * img_size[1], 1))\n",
    "    superres_mask = tf.reshape(superres_mask, (img_size[0] * img_size[1], 1))\n",
    "\n",
    "    superres_IOU = custom_IOU(true_mask, superres_mask, class_id=CLASS_ID)\n",
    "\n",
    "    return superres_IOU.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def compute_superresolution_output(precomputed_data_paths, superres_args, dest_folder, mode=\"slice\", num_aug=100, global_normalize=True, save_output=False):\n",
    "\n",
    "    superres_masks = {}\n",
    "    class_losses = {}\n",
    "    ious = {}\n",
    "\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    for file_path in tqdm(precomputed_data_paths):\n",
    "\n",
    "        file = h5py.File(f\"{file_path}\", \"r\")\n",
    "\n",
    "        if not check_hdf5_validity(file, num_aug=num_aug):\n",
    "            print(f\"File: {file_path} is invalid, skipping...\")\n",
    "            file.close()\n",
    "            continue\n",
    "\n",
    "\n",
    "        filename = file.attrs[\"filename\"]\n",
    "        angles = file[\"angles\"][:]\n",
    "        shifts = file[\"shifts\"][:]\n",
    "\n",
    "        class_masks = file[\"class_masks\"][:]\n",
    "        class_masks = tf.stack(class_masks)\n",
    "\n",
    "        if mode == \"slice\":\n",
    "            max_masks = file[\"max_masks\"][:]\n",
    "            max_masks = tf.stack(max_masks)\n",
    "\n",
    "        file.close()\n",
    "\n",
    "\n",
    "        superresolution_obj = Superresolution(\n",
    "            **superres_args,\n",
    "            num_aug=NUM_AUG,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "\n",
    "        global_min = tf.reduce_min(class_masks) if global_normalize else None\n",
    "        global_max = tf.reduce_max(class_masks) if global_normalize else None\n",
    "\n",
    "        class_masks = tf.map_fn(fn=lambda image: min_max_normalization(image.numpy(), new_min=0.0, new_max=1.0, global_min=global_min, global_max=global_max), elems=class_masks)\n",
    "\n",
    "        target_image_class, class_loss = superresolution_obj.compute_output(class_masks, angles, shifts)\n",
    "        target_image_class = (target_image_class[0]).numpy()\n",
    "        print(f\"Final class loss for image {filename}: {class_loss}\")\n",
    "\n",
    "        if mode == \"slice\":\n",
    "\n",
    "            global_min = tf.reduce_min(max_masks) if global_normalize else None\n",
    "            global_max = tf.reduce_max(max_masks) if global_normalize else None\n",
    "\n",
    "            max_masks = tf.map_fn(fn=lambda image: min_max_normalization(image.numpy(), new_min=0.0, new_max=1.0, global_min=global_min, global_max=global_max), elems=max_masks)\n",
    "\n",
    "\n",
    "            target_image_max, max_loss = superresolution_obj.compute_output(max_masks, angles, shifts)\n",
    "            target_image_max = (target_image_max[0]).numpy()\n",
    "            print(f\"Final max loss for image {filename}: {max_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "        class_losses[filename] = class_loss\n",
    "\n",
    "        th_image = threshold_image(target_image_class, max_mask= None if mode == \"argmax\" else target_image_max)\n",
    "\n",
    "        true_mask_path = os.path.join(DATA_DIR, \"VOCdevkit/VOC2012/SegmentationClassAug\", f\"{filename}.png\")\n",
    "        true_mask = load_image(true_mask_path, image_size=IMG_SIZE, normalize=False,\n",
    "                               is_png=True, resize_method=\"nearest\")\n",
    "\n",
    "        iou = evaluate_IOU(true_mask, th_image)\n",
    "        ious[filename] = iou\n",
    "\n",
    "        # superres_masks[filename] = { \"class\": target_image_class, \"max\": target_image_max } if mode == \"slice\" else target_image_class\n",
    "\n",
    "        if save_output:\n",
    "            tf.keras.utils.save_img(f\"{dest_folder}/{filename}_th_{mode}.png\", th_image, scale=True)\n",
    "\n",
    "\n",
    "\n",
    "    mean_iou = np.mean(np.fromiter(ious.values(), dtype=float))\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"ious.txt\"), \"a\") as f:\n",
    "        f.write(mean_iou)\n",
    "\n",
    "    print(f\"Final Mean IOU: {mean_iou}\")\n",
    "\n",
    "    return 1.0 - mean_iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class SuperresTuner(kt.RandomSearch):\n",
    "\n",
    "    precomputed_data_paths = list_precomputed_data_paths(PRECOMPUTED_OUTPUT_DIR)\n",
    "\n",
    "    def run_trial(self, trial, **kwargs):\n",
    "        hp = trial.hyperparameters\n",
    "\n",
    "        superres_args = {\n",
    "            \"lambda_tv\": hp.Float(\"lambda_tv\", min_value=0.002, max_value= 0.1, step=0.01),\n",
    "            \"lambda_eng\": hp.Float(\"lambda_eng\", min_value=0.001, max_value= 0.1, step=0.01),\n",
    "            \"num_iter\": hp.Int(\"num_iter\", min_value=400, max_value=1000, step=50),\n",
    "            \"learning_rate\" : hp.Float(\"learning_rate\", min_value=1e-4, max_value= 1e-2, step=0.1),\n",
    "        }\n",
    "\n",
    "        return compute_superresolution_output(self.precomputed_data_paths, superres_args, dest_folder=SUPERRES_OUTPUT_DIR, mode=\"slice\",  num_aug=NUM_AUG, global_normalize=False, save_output=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 23m 37s]\n",
      "default_objective: 0.20777671702730172\n",
      "\n",
      "Best default_objective So Far: 0.20755350577812637\n",
      "Total elapsed time: 04h 18m 00s\n",
      "\n",
      "Search: Running Trial #13\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "lambda_tv         |0.082             |0.092             \n",
      "lambda_eng        |0.011             |0.071             \n",
      "num_iter          |1000              |950               \n",
      "learning_rate     |0.0001            |0.0001            \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final class loss for image 2007_008815: 25782.349609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [01:17<32:19, 77.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2007_008815: 55640.72265625\n",
      "Final class loss for image 2007_009346: 21520.96484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/26 [02:35<31:11, 77.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2007_009346: 51747.12890625\n",
      "Final class loss for image 2008_000345: 26179.8828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/26 [03:53<29:52, 77.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_000345: 47305.8671875\n",
      "Final class loss for image 2008_002152: 27288.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4/26 [05:11<28:30, 77.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_002152: 38853.34765625\n",
      "Final class loss for image 2008_002623: 26135.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5/26 [06:28<27:08, 77.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_002623: 55755.4140625\n",
      "Final class loss for image 2008_006341: 31263.8671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6/26 [07:46<25:58, 77.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_006341: 42193.4375\n",
      "Final class loss for image 2008_007548: 18146.265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7/26 [09:04<24:38, 77.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_007548: 38399.296875\n",
      "Final class loss for image 2009_000080: 17032.734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7/26 [10:25<28:18, 89.38s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Temp/ipykernel_13656/2040541666.py\", line 9, in <module>\n",
      "    tuner.search()\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 179, in search\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Temp/ipykernel_13656/1002174236.py\", line 15, in run_trial\n",
      "    return compute_superresolution_output(self.precomputed_data_paths, superres_args, dest_folder=SUPERRES_OUTPUT_DIR, mode=\"slice\",  num_aug=NUM_AUG, global_normalize=False, save_output=True)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Temp/ipykernel_13656/3666301978.py\", line 58, in compute_superresolution_output\n",
      "    target_image_max, max_loss = superresolution_obj.compute_output(max_masks, angles, shifts)\n",
      "  File \"C:\\Users\\alber\\Desktop\\DeeplabV3Plus-TF2\\superresolution.py\", line 58, in compute_output\n",
      "    gradients = tape.gradient(loss, trainable_vars)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 1084, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\", line 71, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1306, in _backward_function_wrapper\n",
      "    return backward._call_flat(  # pylint: disable=protected-access\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1959, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 598, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 58, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Temp/ipykernel_13656/2040541666.py\", line 9, in <module>\n",
      "    tuner.search()\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 179, in search\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Temp/ipykernel_13656/1002174236.py\", line 15, in run_trial\n",
      "    return compute_superresolution_output(self.precomputed_data_paths, superres_args, dest_folder=SUPERRES_OUTPUT_DIR, mode=\"slice\",  num_aug=NUM_AUG, global_normalize=False, save_output=True)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Temp/ipykernel_13656/3666301978.py\", line 58, in compute_superresolution_output\n",
      "    target_image_max, max_loss = superresolution_obj.compute_output(max_masks, angles, shifts)\n",
      "  File \"C:\\Users\\alber\\Desktop\\DeeplabV3Plus-TF2\\superresolution.py\", line 58, in compute_output\n",
      "    gradients = tape.gradient(loss, trainable_vars)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 1084, in gradient\n",
      "    flat_grad = imperative_grad.imperative_grad(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\", line 71, in imperative_grad\n",
      "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1306, in _backward_function_wrapper\n",
      "    return backward._call_flat(  # pylint: disable=protected-access\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1959, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 598, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 58, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_13656/2040541666.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mtuner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;31m#print(tuner.get_best_hyperparameters()[0].get(\"x\"))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001B[0m in \u001B[0;36msearch\u001B[1;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_trial_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 179\u001B[1;33m             \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mfit_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    180\u001B[0m             \u001B[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_13656/1002174236.py\u001B[0m in \u001B[0;36mrun_trial\u001B[1;34m(self, trial, **kwargs)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mcompute_superresolution_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprecomputed_data_paths\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuperres_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdest_folder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mSUPERRES_OUTPUT_DIR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"slice\"\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mnum_aug\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mNUM_AUG\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglobal_normalize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_output\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_13656/3666301978.py\u001B[0m in \u001B[0;36mcompute_superresolution_output\u001B[1;34m(precomputed_data_paths, superres_args, dest_folder, mode, num_aug, global_normalize, save_output)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m             \u001B[0mtarget_image_max\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuperresolution_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_masks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mangles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshifts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     59\u001B[0m             \u001B[0mtarget_image_max\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtarget_image_max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\DeeplabV3Plus-TF2\\superresolution.py\u001B[0m in \u001B[0;36mcompute_output\u001B[1;34m(self, augmented_samples, angles, shifts)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m             \u001B[0mgradients\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainable_vars\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     59\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradients\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainable_vars\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001B[0m in \u001B[0;36mgradient\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1084\u001B[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001B[0m\u001B[0;32m   1085\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001B[0m in \u001B[0;36mimperative_grad\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 71\u001B[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001B[0m\u001B[0;32m     72\u001B[0m       \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_backward_function_wrapper\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m   1305\u001B[0m           \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1306\u001B[1;33m       return backward._call_flat(  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m   1307\u001B[0m           processed_args, remapped_captures)\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1958\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1959\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1960\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    597\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 598\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    599\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2076\u001B[0m                         \u001B[1;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2077\u001B[1;33m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2078\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_ast_nodes\u001B[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001B[0m\n\u001B[0;32m   3376\u001B[0m                         \u001B[0masy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompare\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3377\u001B[1;33m                     \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mawait\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_code\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0masync_\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0masy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3378\u001B[0m                         \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2078\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2079\u001B[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[0;32m   2080\u001B[0m                                             value, tb, tb_offset=tb_offset)\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1367\u001B[1;33m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1267\u001B[1;33m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1124\u001B[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[0;32m   1125\u001B[0m                                                                tb_offset)\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2076\u001B[0m                         \u001B[1;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2077\u001B[1;33m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2078\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\u001B[0m in \u001B[0;36m_pseudo_sync_runner\u001B[1;34m(coro)\u001B[0m\n\u001B[0;32m     66\u001B[0m     \"\"\"\n\u001B[0;32m     67\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 68\u001B[1;33m         \u001B[0mcoro\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     69\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mexc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_cell_async\u001B[1;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001B[0m\n\u001B[0;32m   3183\u001B[0m                     \u001B[0minteractivity\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'async'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3184\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3185\u001B[1;33m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001B[0m\u001B[0;32m   3186\u001B[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001B[0;32m   3187\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_ast_nodes\u001B[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001B[0m\n\u001B[0;32m   3394\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3395\u001B[0m                 \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror_before_exec\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3396\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshowtraceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3397\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3398\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2077\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2078\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2079\u001B[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[0;32m   2080\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[0;32m   2081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1365\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1367\u001B[1;33m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1265\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1267\u001B[1;33m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1269\u001B[0m             )\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1140\u001B[0m         \u001B[0mchained_exc_ids\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1142\u001B[1;33m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001B[0m\u001B[0;32m   1143\u001B[0m                                                                      chained_exceptions_tb_offset)\n\u001B[0;32m   1144\u001B[0m             \u001B[0mexception\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_parts_of_chained_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-tf2\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    380\u001B[0m     \u001B[1;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m     \u001B[1;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "tuner = SuperresTuner(\n",
    "    # No hypermodel or objective specified.\n",
    "    max_trials=30,\n",
    "    overwrite=True,\n",
    "    directory=DATA_DIR,\n",
    "    project_name=\"Tuner_Trials\",\n",
    ")\n",
    "\n",
    "tuner.search()\n",
    "#print(tuner.get_best_hyperparameters()[0].get(\"x\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# super resolution parameters\n",
    "learning_rate = 1e-3\n",
    "lambda_eng = 0.0001 * NUM_AUG\n",
    "lambda_tv = 0.002 * NUM_AUG\n",
    "num_iter = 400\n",
    "\n",
    "\n",
    "precomputed_data_paths = list_precomputed_data_paths(PRECOMPUTED_OUTPUT_DIR)\n",
    "\n",
    "superres_masks_dict, losses = compute_superresolution_output(precomputed_data_paths, mode=\"argmax\", dest_folder=SUPERRES_OUTPUT_DIR, num_aug=NUM_AUG, global_normalize=False, save_output=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "superres_masks_dict_th = {}\n",
    "\n",
    "for key in superres_masks_dict:\n",
    "    target_dict = superres_masks_dict[key]\n",
    "    th_mask = tf.where(target_dict[\"class\"] >= target_dict[\"max\"], CLASS_ID, 0)\n",
    "    superres_masks_dict_th[key] = th_mask.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "superres_masks_dict_th = {}\n",
    "\n",
    "for key in superres_masks_dict:\n",
    "    sample_th = tf.cast(tf.reduce_max(superres_masks_dict[key]), tf.float32) * 0.15\n",
    "    th_mask = tf.where(superres_masks_dict[key] > sample_th, CLASS_ID, 0)\n",
    "    superres_masks_dict_th[key] = th_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def custom_IOU(y_true, y_pred, class_id):\n",
    "    y_true_squeeze = tf.squeeze(y_true)\n",
    "    y_pred_squeeze = tf.squeeze(y_pred)\n",
    "    classes = [0, class_id] # Only check in background and given class\n",
    "\n",
    "    y_true_squeeze = tf.where(y_true_squeeze != class_id, 0, y_true_squeeze)\n",
    "\n",
    "    ious = []\n",
    "    for i in classes:\n",
    "        true_labels = tf.equal(y_true_squeeze, i)\n",
    "        pred_labels = tf.equal(y_pred_squeeze, i)\n",
    "        inter = tf.cast(true_labels & pred_labels, tf.int32)\n",
    "        union = tf.cast(true_labels | pred_labels, tf.int32)\n",
    "\n",
    "        iou = tf.reduce_sum(inter) / tf.reduce_sum(union)\n",
    "        ious.append(iou)\n",
    "\n",
    "    ious = tf.stack(ious)\n",
    "    legal_labels = ~tf.math.is_nan(ious)\n",
    "    ious = tf.gather(ious, indices=tf.where(legal_labels))\n",
    "    return tf.reduce_mean(ious)\n",
    "\n",
    "\n",
    "def evaluate_IOU(true_mask, standard_mask, superres_mask, img_size=(512, 512)):\n",
    "    true_mask = tf.reshape(true_mask, (img_size[0] * img_size[1], 1))\n",
    "    standard_mask = tf.reshape(standard_mask, (img_size[0] * img_size[1], 1))\n",
    "    superres_mask = tf.reshape(superres_mask, (img_size[0] * img_size[1], 1))\n",
    "\n",
    "    # standard_IOU = Mean_IOU(true_mask, standard_mask)\n",
    "    # superres_IOU = Mean_IOU(true_mask, superres_mask)\n",
    "\n",
    "    standard_IOU = custom_IOU(true_mask, standard_mask, class_id=CLASS_ID)\n",
    "    superres_IOU = custom_IOU(true_mask, superres_mask, class_id=CLASS_ID)\n",
    "\n",
    "    return standard_IOU.numpy(), superres_IOU.numpy()\n",
    "\n",
    "def compare_results(image_dict, standard_dict, superres_dict, image_size=(512, 512), verbose=False):\n",
    "    standard_IOUs = []\n",
    "    superres_IOUs = []\n",
    "\n",
    "    for key in image_dict:\n",
    "        true_mask_path = os.path.join(DATA_DIR, \"VOCdevkit/VOC2012/SegmentationClassAug\", f\"{key}.png\")\n",
    "        true_mask = load_image(true_mask_path, image_size=image_size, normalize=False,\n",
    "                               is_png=True, resize_method=\"nearest\")\n",
    "\n",
    "        standard_mask = standard_dict[key]\n",
    "        superres_image = superres_dict[key]\n",
    "\n",
    "        standard_IOU, superres_IOU = evaluate_IOU(true_mask, standard_mask, superres_image, img_size=image_size)\n",
    "        standard_IOUs.append(standard_IOU)\n",
    "        superres_IOUs.append(superres_IOU)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"IOUs for image {key} - Standard: {str(standard_IOU)}, Superres: {str(superres_IOU)}\")\n",
    "\n",
    "    return standard_IOUs, superres_IOUs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "standard_IOUs, superres_IOUs = compare_results(images_dict, standard_masks_dict, superres_masks_dict_th, image_size=IMG_SIZE, verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard mean IOU: 0.8432970924901599,  Superres mean IOU: 0.8232844974653806\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard mean IOU: {np.mean(standard_IOUs)},  Superres mean IOU: {np.mean(superres_IOUs)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_standard_superres(input_image, ground_truth, standard_mask, superres_mask):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(input_image))\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(ground_truth), alpha=0.5)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Sandard predicted Mask\")\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(input_image))\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(standard_mask), alpha=0.5)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Superresolution Mask\")\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(input_image))\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(superres_mask), alpha=0.5)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_key = random.choice(valid_filenames)\n",
    "sample_image = images_dict[sample_key]\n",
    "sample_standard = standard_masks_dict[sample_key]\n",
    "sample_superres = superres_masks_dict[sample_key][\"class\"]\n",
    "sample_superres_th = superres_masks_dict_th[sample_key]\n",
    "\n",
    "true_mask_path = os.path.join(DATA_DIR, \"VOCdevkit/VOC2012/SegmentationClassAug\", f\"{sample_key}.png\")\n",
    "true_mask = load_image(true_mask_path, image_size=IMG_SIZE, normalize=False, is_png=True, resize_method=\"nearest\")\n",
    "\n",
    "#plot_prediction([sample_image, true_mask, sample_standard], only_prediction=False, show_overlay=True)\n",
    "#print_labels([true_mask, sample_standard])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot_image(sample_superres_th)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_standard_superres(sample_image, true_mask, sample_standard, sample_superres)\n",
    "plot_standard_superres(sample_image, true_mask, sample_standard, sample_superres_th)\n",
    "evaluate_IOU(true_mask, sample_standard, sample_superres_th)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5096/1112307316.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msuperres_masks_dict\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[0mtarget_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuperres_masks_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m         \u001B[0mtarget_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtarget_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"class\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0mth_mask_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduce_max\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtarget_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mth_value\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "th_ranges = np.arange(0.50, 1.0, 0.05)\n",
    "results = {}\n",
    "\n",
    "for th_value in th_ranges:\n",
    "    superres_masks_dict_th_test = {}\n",
    "    for key in superres_masks_dict:\n",
    "        target_dict = superres_masks_dict[key]\n",
    "        target_mask = target_dict[\"class\"]\n",
    "\n",
    "        th_mask_value = tf.cast(tf.reduce_max(target_mask), tf.float32) * th_value\n",
    "        th_mask = tf.where(target_mask > th_mask_value, CLASS_ID, 0)\n",
    "        superres_masks_dict_th_test[key] = th_mask.numpy()\n",
    "\n",
    "    standard_IOUs, superres_IOUs = compare_results(images_dict, standard_masks_dict, superres_masks_dict_th_test, image_size=IMG_SIZE, verbose=False)\n",
    "\n",
    "    mean_standard_IOUs = np.mean(standard_IOUs)\n",
    "    mean_superres_IOUs = np.mean(superres_IOUs)\n",
    "    results[th_value] = (mean_standard_IOUs, mean_superres_IOUs)\n",
    "    print(f\"Threshold Value: {th_value} -- Standard mean IOU: {np.mean(standard_IOUs)},  Superres mean IOU: {np.mean(superres_IOUs)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_image(augmented_features_dict[sample_key][\"class\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "ax = sns.heatmap(a[..., -1], annot=True, cbar=False, fmt=\".2f\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}