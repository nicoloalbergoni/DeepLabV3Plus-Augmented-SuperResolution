{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "#\n",
    "# !git clone -b parameters_search https://{TOKEN}@github.com/nicoloalbergoni/DeeplabV3Plus-TF2.git\n",
    "# %load_ext tensorboard\n",
    "# %cd ./DeeplabV3Plus-TF2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#!python download_and_prepare_voc.py --remove_cmap --download_berkley"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from model import DeeplabV3Plus\n",
    "import tensorflow_addons as tfa\n",
    "from matplotlib import pyplot as plt\n",
    "from superresolution_scripts.superresolution import Superresolution\n",
    "from utils import load_image, get_prediction, create_mask, plot_prediction\n",
    "from superresolution_scripts.superres_utils import get_img_paths, filter_by_class, min_max_normalization, plot_image, plot_histogram, list_precomputed_data_paths, check_hdf5_validity\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "PASCAL_ROOT = os.path.join(DATA_DIR, \"VOCdevkit\", \"VOC2012\")\n",
    "IMGS_PATH = os.path.join(PASCAL_ROOT, \"JPEGImages\")\n",
    "\n",
    "SUPERRES_ROOT = os.path.join(DATA_DIR, \"superres_root\")\n",
    "PRECOMPUTED_OUTPUT_DIR = os.path.join(SUPERRES_ROOT, \"precomputed_features\")\n",
    "STANDARD_OUTPUT_DIR = os.path.join(SUPERRES_ROOT, \"standard_output\")\n",
    "SUPERRES_OUTPUT_DIR = os.path.join(SUPERRES_ROOT, \"superres_output\")\n",
    "\n",
    "# SEED = np.random.randint(0, 1000)\n",
    "SEED = 1234\n",
    "IMG_SIZE = (512, 512)\n",
    "BATCH_SIZE = 1\n",
    "BUFFER_SIZE = 1000\n",
    "EPOCHS = 30\n",
    "CLASSES = 21\n",
    "RESHAPE_MASKS = True\n",
    "NUM_AUG = 50\n",
    "CLASS_ID = 8\n",
    "NUM_SAMPLES = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid images: 28 (Initial:  300)\n"
     ]
    }
   ],
   "source": [
    "image_list_path = os.path.join(DATA_DIR, \"augmented_file_lists\", \"trainaug.txt\")\n",
    "image_paths = get_img_paths(image_list_path, IMGS_PATH)\n",
    "\n",
    "if NUM_SAMPLES is not None:\n",
    "    image_paths = image_paths[:NUM_SAMPLES]\n",
    "\n",
    "images_dict = filter_by_class(image_paths, class_id=CLASS_ID)\n",
    "\n",
    "print(f\"Valid images: {len(images_dict)} (Initial:  {len(image_paths)})\")\n",
    "\n",
    "valid_filenames = list(images_dict.keys())\n",
    "\n",
    "model_no_upsample = DeeplabV3Plus(\n",
    "    input_shape=(512, 512, 3),\n",
    "    classes=21,\n",
    "    OS=16,\n",
    "    last_activation=None,\n",
    "    load_weights=True,\n",
    "    backbone=\"mobilenet\",\n",
    "    alpha=1.).build_model(final_upsample=False)\n",
    "\n",
    "model_standard = DeeplabV3Plus(\n",
    "    input_shape=(512, 512, 3),\n",
    "    classes=21,\n",
    "    OS=16,\n",
    "    last_activation=None,\n",
    "    load_weights=True,\n",
    "    backbone=\"mobilenet\",\n",
    "    alpha=1.).build_model(final_upsample=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute standard output for comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_standard_output(image_dict, model, dest_folder, filter_class_id=None):\n",
    "    standard_masks = {}\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    for key in tqdm(image_dict):\n",
    "        standard_mask = get_prediction(model, image_dict[key])\n",
    "        if filter_class_id is not None:\n",
    "            standard_mask = tf.where(standard_mask == filter_class_id, standard_mask, 0) # Set to 0 all predictions different from the given class\n",
    "        tf.keras.utils.save_img(f\"{dest_folder}/{key}.png\", standard_mask, scale=False)\n",
    "        standard_masks[key] = standard_mask\n",
    "\n",
    "    return standard_masks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:07<00:00,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "standard_masks_dict = compute_standard_output(images_dict, model_standard, dest_folder=STANDARD_OUTPUT_DIR, filter_class_id=CLASS_ID)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Precompute Augmented Output Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_augmented_copies(image, num_aug, angle_max, shift_max, chunk_size=20):\n",
    "\n",
    "    if (num_aug % chunk_size) != 0:\n",
    "        raise Exception(\"Num aug must be a multiple of 50\")\n",
    "\n",
    "    num_chunks = num_aug // chunk_size\n",
    "\n",
    "    angles = np.random.uniform(-angle_max, angle_max, num_aug)\n",
    "    shifts = np.random.uniform(-shift_max, shift_max, (num_aug, 2))\n",
    "    angles[0] = 0\n",
    "    shifts[0] = np.array([0, 0])\n",
    "    angles = angles.astype(\"float32\")\n",
    "    shifts = shifts.astype(\"float32\")\n",
    "\n",
    "    angles_chunks = np.split(angles, num_chunks)\n",
    "    shifts_chunks = np.split(shifts, num_chunks)\n",
    "\n",
    "    augmented_chunks = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        images_chunk = tf.tile(tf.expand_dims(image, axis=0), [chunk_size, 1, 1, 1])\n",
    "        rotated_chunk = tfa.image.rotate(images_chunk, angles_chunks[i], interpolation=\"bilinear\")\n",
    "        translated_chunk= tfa.image.translate(rotated_chunk, shifts_chunks[i], interpolation=\"bilinear\")\n",
    "        augmented_chunks.append(translated_chunk.numpy())\n",
    "\n",
    "    #augmented_copies = np.concatenate(augmented_chunks, axis=0)\n",
    "\n",
    "    return augmented_chunks, angles, shifts\n",
    "\n",
    "def compute_augmented_features(image_filenames, model, dest_folder, filter_class_id, mode=\"slice\", num_aug=100, angle_max=0.5, shift_max=30, save_output=False, relu_output=False):\n",
    "\n",
    "    augmented_features = {}\n",
    "\n",
    "    for filename in tqdm(image_filenames):\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(IMGS_PATH, f\"{filename}.jpg\")\n",
    "        image = load_image(image_path, image_size=IMG_SIZE, normalize=True)\n",
    "\n",
    "        # Create augmented copies\n",
    "        augmented_images, angles, shifts = create_augmented_copies(image, num_aug=num_aug, angle_max=angle_max, shift_max=shift_max, chunk_size=1)\n",
    "\n",
    "        # Create destination folder\n",
    "        output_folder = os.path.join(dest_folder, filename)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        class_masks = []\n",
    "        max_masks = []\n",
    "\n",
    "        for i, augmented_copy in enumerate(augmented_images):\n",
    "            predictions = model.predict(augmented_copy, batch_size=BATCH_SIZE)\n",
    "            prediction = predictions[0]\n",
    "\n",
    "            if mode == \"slice\":\n",
    "                class_slice = prediction[:, :, filter_class_id]\n",
    "                class_mask = class_slice[..., np.newaxis]\n",
    "\n",
    "                no_class_prediction = np.delete(prediction, filter_class_id, axis=-1)\n",
    "                max_mask = no_class_prediction.max(axis=-1)\n",
    "                max_mask = max_mask[..., np.newaxis]\n",
    "\n",
    "                # ReLU is only needed when working with slices\n",
    "                if relu_output:\n",
    "                    class_mask = (tf.nn.relu(class_mask)).numpy()\n",
    "                    max_mask = (tf.nn.relu(max_mask)).numpy()\n",
    "\n",
    "                max_masks.append(max_mask)\n",
    "\n",
    "            elif mode == \"argmax\":\n",
    "                class_mask = create_mask(prediction)\n",
    "                # Set to 0 all predictions different from the given class\n",
    "                class_mask = tf.where(class_mask == filter_class_id, class_mask, 0)\n",
    "                class_mask = tf.cast(class_mask, tf.float32) # Necessary for super-resolution operations\n",
    "                class_mask = class_mask.numpy()\n",
    "\n",
    "            class_masks.append(class_mask)\n",
    "\n",
    "            if save_output:\n",
    "                tf.keras.utils.save_img(f\"{output_folder}/{i}_class.png\", class_mask, scale=True)\n",
    "                if mode == \"slice\":\n",
    "                    tf.keras.utils.save_img(f\"{output_folder}/{i}_max.png\", max_mask, scale=True)\n",
    "\n",
    "            # np.save(os.path.join(output_folder, f\"{filename}_angles\"), angles)\n",
    "            # np.save(os.path.join(output_folder, f\"{filename}_shifts\"), shifts)\n",
    "\n",
    "        file = h5py.File(f\"{output_folder}/{filename}.hdf5\", \"w\")\n",
    "        file.create_dataset(\"class_masks\", data=class_masks)\n",
    "\n",
    "        if mode == \"slice\":\n",
    "            file.create_dataset(\"max_masks\", data=max_masks)\n",
    "\n",
    "        file.create_dataset(\"angles\", data=angles)\n",
    "        file.create_dataset(\"shifts\", data=shifts)\n",
    "        file.attrs[\"filename\"] = filename\n",
    "        file.attrs[\"mode\"] = mode\n",
    "\n",
    "        file.close()\n",
    "\n",
    "        augmented_features[filename] = { \"class\": class_masks, \"max\": max_masks }\n",
    "\n",
    "    return augmented_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [03:07<00:00,  6.69s/it]\n"
     ]
    }
   ],
   "source": [
    "angle_max = 0.5  # in radians\n",
    "shift_max = 30\n",
    "\n",
    "augmented_features_dict = compute_augmented_features(images_dict, model_no_upsample, mode=\"slice\", dest_folder=PRECOMPUTED_OUTPUT_DIR, filter_class_id=CLASS_ID, num_aug=NUM_AUG, angle_max=angle_max, shift_max=shift_max, save_output=True, relu_output=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute Super-Resolution Output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def threshold_image(class_mask, max_mask=None, th_val=.15):\n",
    "    if max_mask is not None:\n",
    "        th_mask = tf.where(class_mask >= max_mask, CLASS_ID, 0)\n",
    "    else:\n",
    "        sample_th = tf.cast(tf.reduce_max(class_mask), tf.float32) * th_val\n",
    "        th_mask = tf.where(class_mask > sample_th, CLASS_ID, 0)\n",
    "\n",
    "    return th_mask.numpy()\n",
    "\n",
    "\n",
    "def custom_IOU(y_true, y_pred, class_id):\n",
    "    y_true_squeeze = tf.squeeze(y_true)\n",
    "    y_pred_squeeze = tf.squeeze(y_pred)\n",
    "    classes = [0, class_id] # Only check in background and given class\n",
    "\n",
    "    y_true_squeeze = tf.where(y_true_squeeze != class_id, 0, y_true_squeeze)\n",
    "\n",
    "    ious = []\n",
    "    for i in classes:\n",
    "        true_labels = tf.equal(y_true_squeeze, i)\n",
    "        pred_labels = tf.equal(y_pred_squeeze, i)\n",
    "        inter = tf.cast(true_labels & pred_labels, tf.int32)\n",
    "        union = tf.cast(true_labels | pred_labels, tf.int32)\n",
    "\n",
    "        iou = tf.reduce_sum(inter) / tf.reduce_sum(union)\n",
    "        ious.append(iou)\n",
    "\n",
    "    ious = tf.stack(ious)\n",
    "    legal_labels = ~tf.math.is_nan(ious)\n",
    "    ious = tf.gather(ious, indices=tf.where(legal_labels))\n",
    "    return tf.reduce_mean(ious)\n",
    "\n",
    "\n",
    "def evaluate_IOU(true_mask, superres_mask, img_size=(512, 512)):\n",
    "    true_mask = tf.reshape(true_mask, (img_size[0] * img_size[1], 1))\n",
    "    superres_mask = tf.reshape(superres_mask, (img_size[0] * img_size[1], 1))\n",
    "\n",
    "    superres_IOU = custom_IOU(true_mask, superres_mask, class_id=CLASS_ID)\n",
    "\n",
    "    return superres_IOU.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def compute_superresolution_output(precomputed_data_paths, superres_args, dest_folder, mode=\"slice\", num_aug=100, global_normalize=True, save_output=False):\n",
    "\n",
    "    superres_masks = {}\n",
    "    class_losses = {}\n",
    "    ious = {}\n",
    "\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    for file_path in tqdm(precomputed_data_paths):\n",
    "\n",
    "        file = h5py.File(f\"{file_path}\", \"r\")\n",
    "\n",
    "        if not check_hdf5_validity(file, num_aug=num_aug):\n",
    "            print(f\"File: {file_path} is invalid, skipping...\")\n",
    "            file.close()\n",
    "            continue\n",
    "\n",
    "\n",
    "        filename = file.attrs[\"filename\"]\n",
    "        angles = file[\"angles\"][:]\n",
    "        shifts = file[\"shifts\"][:]\n",
    "\n",
    "        class_masks = file[\"class_masks\"][:]\n",
    "        class_masks = tf.stack(class_masks)\n",
    "\n",
    "        if mode == \"slice\":\n",
    "            max_masks = file[\"max_masks\"][:]\n",
    "            max_masks = tf.stack(max_masks)\n",
    "\n",
    "        file.close()\n",
    "\n",
    "\n",
    "        superresolution_obj = Superresolution(\n",
    "            **superres_args,\n",
    "            num_aug=NUM_AUG,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "\n",
    "        global_min = tf.reduce_min(class_masks) if global_normalize else None\n",
    "        global_max = tf.reduce_max(class_masks) if global_normalize else None\n",
    "\n",
    "        class_masks = tf.map_fn(fn=lambda image: min_max_normalization(image.numpy(), new_min=0.0, new_max=1.0, global_min=global_min, global_max=global_max), elems=class_masks)\n",
    "\n",
    "        target_image_class, class_loss = superresolution_obj.compute_output(class_masks, angles, shifts)\n",
    "        target_image_class = (target_image_class[0]).numpy()\n",
    "        print(f\"Final class loss for image {filename}: {class_loss}\")\n",
    "\n",
    "        if mode == \"slice\":\n",
    "\n",
    "            global_min = tf.reduce_min(max_masks) if global_normalize else None\n",
    "            global_max = tf.reduce_max(max_masks) if global_normalize else None\n",
    "\n",
    "            max_masks = tf.map_fn(fn=lambda image: min_max_normalization(image.numpy(), new_min=0.0, new_max=1.0, global_min=global_min, global_max=global_max), elems=max_masks)\n",
    "\n",
    "\n",
    "            target_image_max, max_loss = superresolution_obj.compute_output(max_masks, angles, shifts)\n",
    "            target_image_max = (target_image_max[0]).numpy()\n",
    "            print(f\"Final max loss for image {filename}: {max_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "        class_losses[filename] = class_loss\n",
    "\n",
    "        th_image = threshold_image(target_image_class, max_mask= None if mode == \"argmax\" else target_image_max)\n",
    "\n",
    "        true_mask_path = os.path.join(DATA_DIR, \"VOCdevkit/VOC2012/SegmentationClassAug\", f\"{filename}.png\")\n",
    "        true_mask = load_image(true_mask_path, image_size=IMG_SIZE, normalize=False,\n",
    "                               is_png=True, resize_method=\"nearest\")\n",
    "\n",
    "        iou = evaluate_IOU(true_mask, th_image)\n",
    "        ious[filename] = iou\n",
    "\n",
    "        # superres_masks[filename] = { \"class\": target_image_class, \"max\": target_image_max } if mode == \"slice\" else target_image_class\n",
    "\n",
    "        if save_output:\n",
    "            tf.keras.utils.save_img(f\"{dest_folder}/{filename}_th_{mode}.png\", th_image, scale=True)\n",
    "\n",
    "\n",
    "\n",
    "    mean_iou = np.mean(np.fromiter(ious.values(), dtype=float))\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"ious.txt\"), \"a\") as f:\n",
    "        f.write(str(mean_iou))\n",
    "\n",
    "    print(f\"Final Mean IOU: {mean_iou}\")\n",
    "\n",
    "    return mean_iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class SuperresTuner(kt.RandomSearch):\n",
    "\n",
    "    precomputed_data_paths = list_precomputed_data_paths(PRECOMPUTED_OUTPUT_DIR)\n",
    "\n",
    "    def run_trial(self, trial, **kwargs):\n",
    "        hp = trial.hyperparameters\n",
    "\n",
    "        superres_args = {\n",
    "            \"lambda_tv\": hp.Float(\"lambda_tv\", min_value=0.01, max_value= 2.0),\n",
    "            \"lambda_eng\": hp.Float(\"lambda_eng\", min_value=0.01, max_value= 4.0),\n",
    "            # \"num_iter\": hp.Int(\"num_iter\", min_value=400, max_value=800, step=50),\n",
    "            \"num_iter\": 450,\n",
    "            \"learning_rate\" : 1e-3,\n",
    "            \"loss_coeff\": False\n",
    "        }\n",
    "\n",
    "        global_normalize = hp.Boolean(\"global_normalize\")\n",
    "\n",
    "        run = wandb.init(project=\"tesi\", entity=\"albergoni-nicolo\", config=hp.values)\n",
    "\n",
    "        wandb.config.num_aug = NUM_AUG\n",
    "        wandb.config.num_sample = NUM_SAMPLES\n",
    "        wandb.config.batch_size = BATCH_SIZE\n",
    "        wandb.config.class_id = CLASS_ID\n",
    "        wandb.config.num_iter = superres_args[\"num_iter\"]\n",
    "        wandb.config.lr = superres_args[\"learning_rate\"]\n",
    "\n",
    "        metric = compute_superresolution_output(self.precomputed_data_paths, superres_args, dest_folder=SUPERRES_OUTPUT_DIR, mode=\"slice\",  num_aug=NUM_AUG, global_normalize=global_normalize, save_output=False)\n",
    "\n",
    "        run.log({\"mean_iou\": metric})\n",
    "        run.finish()\n",
    "\n",
    "        return 1.0 - metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 16m 07s]\n",
      "default_objective: 0.19009071489183438\n",
      "\n",
      "Best default_objective So Far: 0.1871141352243717\n",
      "Total elapsed time: 03h 03m 28s\n",
      "\n",
      "Search: Running Trial #12\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "lambda_tv         |1.0771            |0.64153           \n",
      "lambda_eng        |0.1033            |3.2461            \n",
      "global_normalize  |True              |False             \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.11"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\alber\\Desktop\\DeepLabV3Plus-Augmented-SuperResolution\\wandb\\run-20220314_152605-10jm2krm</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/albergoni-nicolo/Tesi/runs/10jm2krm\" target=\"_blank\">cheese-cobbler-15</a></strong> to <a href=\"https://wandb.ai/albergoni-nicolo/Tesi\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final class loss for image 2007_000549: 43852.5078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1/28 [00:34<15:32, 34.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2007_000549: 41554.49609375\n",
      "Final class loss for image 2007_008575: 36317.2578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [01:08<14:50, 34.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2007_008575: 35405.26171875\n",
      "Final class loss for image 2008_003045: 20481.033203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3/28 [01:42<14:15, 34.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_003045: 26439.994140625\n",
      "Final class loss for image 2008_003303: 30530.556640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/28 [02:16<13:39, 34.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_003303: 34760.953125\n",
      "Final class loss for image 2008_005247: 29567.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5/28 [02:50<13:04, 34.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_005247: 37691.1953125\n",
      "Final class loss for image 2008_005337: 26201.767578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 6/28 [03:24<12:30, 34.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_005337: 26677.42578125\n",
      "Final class loss for image 2008_006099: 35317.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7/28 [03:59<11:58, 34.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_006099: 23447.47265625\n",
      "Final class loss for image 2008_007130: 41553.98828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 8/28 [04:33<11:23, 34.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_007130: 28955.421875\n",
      "Final class loss for image 2008_007324: 21571.22265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 9/28 [05:07<10:48, 34.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2008_007324: 34852.23828125\n",
      "Final class loss for image 2009_000150: 22653.88671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 10/28 [05:41<10:14, 34.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2009_000150: 37652.671875\n",
      "Final class loss for image 2009_000304: 20930.33984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 11/28 [06:16<09:43, 34.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2009_000304: 38466.48828125\n",
      "Final class loss for image 2009_002053: 32469.7890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 12/28 [06:52<09:16, 34.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max loss for image 2009_002053: 45885.421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 12/28 [07:02<09:22, 35.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_28432/1610068662.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m )\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mtuner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001B[0m in \u001B[0;36msearch\u001B[1;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    178\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_trial_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 179\u001B[1;33m             \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mfit_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    180\u001B[0m             \u001B[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    181\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mresults\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_28432/1835165104.py\u001B[0m in \u001B[0;36mrun_trial\u001B[1;34m(self, trial, **kwargs)\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[0mwandb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuperres_args\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"learning_rate\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m         \u001B[0mmetric\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompute_superresolution_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprecomputed_data_paths\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuperres_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdest_folder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mSUPERRES_OUTPUT_DIR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"slice\"\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mnum_aug\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mNUM_AUG\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglobal_normalize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mglobal_normalize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_output\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m         \u001B[0mrun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlog\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"mean_iou\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mmetric\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_28432/2644566550.py\u001B[0m in \u001B[0;36mcompute_superresolution_output\u001B[1;34m(precomputed_data_paths, superres_args, dest_folder, mode, num_aug, global_normalize, save_output)\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[0mclass_masks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mmin_max_normalization\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnew_min\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnew_max\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglobal_min\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mglobal_min\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglobal_max\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mglobal_max\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0melems\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mclass_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m         \u001B[0mtarget_image_class\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuperresolution_obj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclass_masks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mangles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshifts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     47\u001B[0m         \u001B[0mtarget_image_class\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtarget_image_class\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Final class loss for image {filename}: {class_loss}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\DeepLabV3Plus-Augmented-SuperResolution\\superresolution_scripts\\superresolution.py\u001B[0m in \u001B[0;36mcompute_output\u001B[1;34m(self, augmented_samples, angles, shifts)\u001B[0m\n\u001B[0;32m     57\u001B[0m             \u001B[1;31m# optimizer.minimize(lambda: self.loss_function(target_image, augmented_samples), var_list=[target_image])\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m                 \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtarget_image\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maugmented_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mangles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshifts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;36m10\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_iter\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    909\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 910\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    911\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    912\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    947\u001B[0m       \u001B[1;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    948\u001B[0m       \u001B[1;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 949\u001B[1;33m       \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    950\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_created_variables\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    951\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3127\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3128\u001B[0m       (graph_function,\n\u001B[1;32m-> 3129\u001B[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0m\u001B[0;32m   3130\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m   3131\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3508\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_signature\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0margs\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3509\u001B[0m       \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflat_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3510\u001B[1;33m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_spec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanonicalize_function_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3511\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3512\u001B[0m       \u001B[0mflat_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcanonicalize_function_inputs\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2870\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2871\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_input_signature\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2872\u001B[1;33m       \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflat_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfiltered_flat_inputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_numpy_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2873\u001B[0m       \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflat_kwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfiltered_flat_kwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_numpy_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2874\u001B[0m       \u001B[0mflat_inputs\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mflat_kwargs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_convert_numpy_inputs\u001B[1;34m(inputs)\u001B[0m\n\u001B[0;32m   2932\u001B[0m         raise TypeError(f\"The output of __array__ must be an np.ndarray, \"\n\u001B[0;32m   2933\u001B[0m                         f\"got {type(a)} from {value}.\")\n\u001B[1;32m-> 2934\u001B[1;33m       \u001B[0mflat_inputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2935\u001B[0m       \u001B[0mfiltered_flat_inputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflat_inputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2936\u001B[0m       \u001B[0mneed_packing\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[1;34m(value, dtype, shape, name)\u001B[0m\n\u001B[0;32m    269\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mcalled\u001B[0m \u001B[0mon\u001B[0m \u001B[0ma\u001B[0m \u001B[0msymbolic\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    270\u001B[0m   \"\"\"\n\u001B[1;32m--> 271\u001B[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0m\u001B[0;32m    272\u001B[0m                         allow_broadcast=True)\n\u001B[0;32m    273\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[0;32m    281\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"tf.constant\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    282\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 283\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    284\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    285\u001B[0m   \u001B[0mg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\alber\\desktop\\deeplabv3plus-augmented-superresolution\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36m_constant_eager_impl\u001B[1;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    307\u001B[0m   \u001B[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 308\u001B[1;33m   \u001B[0mt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    309\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "tuner = SuperresTuner(\n",
    "    # No hypermodel or objective specified.\n",
    "    max_trials=30,\n",
    "    overwrite=True,\n",
    "    directory=DATA_DIR,\n",
    "    project_name=\"Tuner_Trials\",\n",
    ")\n",
    "\n",
    "tuner.search()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].get(\"lambda_tv\"))\n",
    "print(tuner.get_best_hyperparameters()[0].get(\"lambda_eng\"))\n",
    "print(tuner.get_best_hyperparameters()[0].get(\"global_normalize\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}